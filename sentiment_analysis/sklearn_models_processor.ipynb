{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b011e8df-b4e9-47c4-a9cc-6d47674d0fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74e4a5a7-ab32-4b70-9eeb-599ff31a4c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  one best crichton novel sphere michael crichto...      1\n",
      "1  medicine future z accomplished heart surgeon f...      1\n",
      "2  beautiful gorgeous network comic book contains...      1\n",
      "3  lover robicheaux book lover robicheaux demon s...      1\n",
      "4  excellent broad survey development civilizatio...      1\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('reviews_dataset2.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8df4fa2-1e70-4c7d-8e8d-8abf710e8b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bfb8a1f-2cf5-42e0-af94-7ab2f5770dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For CountVectorizerMultinomialNB:\n",
      "Accuracy: 0.8710440418184399\n",
      "Next chunk of models was finished\n",
      "For TfidfVectorizerMultinomialNB:\n",
      "Accuracy: 0.8492833151993945\n",
      "Next chunk of models was finished\n",
      "For HashingVectorizerMultinomialNB:\n",
      "Accuracy: 0.810255925067411\n",
      "Next chunk of models was finished\n",
      "For TfidfVectorizerLogisticRegression:\n",
      "Accuracy: 0.9025970954160556\n",
      "Next chunk of models was finished\n",
      "For HashingVectorizerLogisticRegression:\n",
      "Accuracy: 0.9003737168267184\n",
      "Next chunk of models was finished\n",
      "For CountVectorizerLogisticRegression:\n",
      "Accuracy: 0.9003737168267184\n",
      "Next chunk of models was finished\n",
      "For CountVectorizerGradientBoostingClassifier:\n",
      "Accuracy: 0.8560480628222716\n",
      "Next chunk of models was finished\n",
      "For TfidfVectorizerRandomForestClassifier:\n",
      "Accuracy: 0.8744027626661621\n",
      "Next chunk of models was finished\n",
      "For TfidfVectorizerGradientBoostingClassifier:\n",
      "Accuracy: 0.8594067836699939\n",
      "Next chunk of models was finished\n",
      "For CountVectorizerRandomForestClassifier:\n",
      "Accuracy: 0.8519324471356261\n",
      "Next chunk of models was finished\n",
      "For HashingVectorizerGradientBoostingClassifier:\n",
      "Accuracy: 0.8598325370168882\n",
      "Next chunk of models was finished\n",
      "For TfidfVectorizerSVC:\n",
      "Accuracy: 0.9064288755381049\n",
      "Next chunk of models was finished\n",
      "For HashingVectorizerSVC:\n",
      "Accuracy: 0.9071857703770282\n",
      "Next chunk of models was finished\n",
      "For HashingVectorizerRandomForestClassifier:\n",
      "Accuracy: 0.8290836841856285\n",
      "Next chunk of models was finished\n",
      "For CountVectorizerSVC:\n",
      "Accuracy: 0.8842897014995978\n",
      "Next chunk of models was finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import multiprocessing\n",
    "\n",
    "vectorizers = [\n",
    "    TfidfVectorizer(max_features=7000),\n",
    "    CountVectorizer(),\n",
    "    HashingVectorizer(n_features=2**20, alternate_sign=False)\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(max_iter=1000),\n",
    "    SVC(kernel='linear'),\n",
    "    RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "]\n",
    "\n",
    "models = []\n",
    "\n",
    "for vectorizer in vectorizers:\n",
    "    for classifier in classifiers:\n",
    "        model = Pipeline([\n",
    "            ('vectorizer', vectorizer),\n",
    "            ('classifier', classifier)\n",
    "        ])\n",
    "\n",
    "        models.append((type(vectorizer).__name__ + type(classifier).__name__, model))\n",
    "\n",
    "def train_model(name_model):\n",
    "    name, model = name_model\n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    print(f'For {name}:')\n",
    "    #print(classification_report(y_test, y_pred))\n",
    "    print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "    return (name, model)\n",
    "\n",
    "def train_models(models):\n",
    "    results = [train_model(model) for model in models]\n",
    "    print('Next chunk of models was finished')\n",
    "    return results\n",
    "\n",
    "chunk_size = 1\n",
    "chunks = [models[i:i + chunk_size] for i in range(0, len(models), chunk_size)]\n",
    "\n",
    "#with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "#    results = list(executor.map(spelling_corrections, chunks))\n",
    "with multiprocessing.Pool() as pool:\n",
    "    result_models = pool.map(train_models, chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ffc891dc-e508-4413-a79c-3689e42209d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "TfidfVectorizerMultinomialNB\n",
      "TfidfVectorizerLogisticRegression\n",
      "TfidfVectorizerSVC\n",
      "TfidfVectorizerRandomForestClassifier\n",
      "TfidfVectorizerGradientBoostingClassifier\n",
      "CountVectorizerMultinomialNB\n",
      "CountVectorizerLogisticRegression\n",
      "CountVectorizerSVC\n",
      "CountVectorizerRandomForestClassifier\n",
      "CountVectorizerGradientBoostingClassifier\n",
      "HashingVectorizerMultinomialNB\n",
      "HashingVectorizerLogisticRegression\n",
      "HashingVectorizerSVC\n",
      "Found!\n",
      "HashingVectorizerRandomForestClassifier\n",
      "HashingVectorizerGradientBoostingClassifier\n"
     ]
    }
   ],
   "source": [
    "# save best model to file\n",
    "import pickle\n",
    "\n",
    "print(len(result_models))\n",
    "\n",
    "for models in result_models:\n",
    "    name, model = models[0]\n",
    "    print(name)\n",
    "    if name == \"HashingVectorizerSVC\":\n",
    "        print(\"Found!\")\n",
    "        with open('HashingVectorizerSVC.pkl', 'wb') as file:\n",
    "            pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ef9c77-0980-46de-94dc-57bc3edfba93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using GridSearchCV to try to find best parameters\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'vectorizer__max_features': [100, 500, 1000, 2000],\n",
    "    'classifier__C': [0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "print(f\"The best parameters: {grid_search.best_params_}\")\n",
    "y_pred = grid_search.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca25c34-9ec6-4896-8927-3ef3ebd893b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using StackingClassifier to mix most successful models in one\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators = [\n",
    "    ('lr', LogisticRegression(max_iter=1000)),\n",
    "    ('svm', SVC(kernel='linear', probability=True))\n",
    "]\n",
    "\n",
    "model_stacking = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(max_features=7000)),\n",
    "    ('classifier', StackingClassifier(estimators=estimators))\n",
    "])\n",
    "\n",
    "model_stacking.fit(x_train, y_train)\n",
    "y_pred = model_stacking.predict(x_test)\n",
    "print(\"Stacking Classifier\")\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39324757-8262-4210-91ed-70041743c02c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
